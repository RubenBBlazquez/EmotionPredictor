{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numpy import random\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import mediapipe as mp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = load_model('models/facialPointsPredictor.h5')\n",
    "model_emotions = load_model('models/emotionPredictor.h5')\n",
    "emotion_dict = {0: 'Ira', 1: 'Asco', 2: 'Tristeza', 3: 'Felicidad', 4: 'Sorpresa'}\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SetFiltersActions:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.last_emotion_predicted = ''\n",
    "        self.second_frame = None\n",
    "        self.random_filter = 'filtros/sunglasses.png'\n",
    "\n",
    "    def get_points(self, image):\n",
    "        image = tf.reshape(image, (96, 96, 1))\n",
    "        points = model.predict(np.array([image]))[0]\n",
    "\n",
    "        return points[0::2], points[1::2]\n",
    "\n",
    "\n",
    "    def enumerate_points(self, points: list[tuple]):\n",
    "        \"\"\"Enumerate points in a list of tuples each tuple item is one more index\"\"\"\n",
    "        return list(enumerate(points))\n",
    "\n",
    "    def draw_rectangles(self, frame):\n",
    "        cv2.rectangle(frame, (0, 0), (100, 100), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, 'Change FT', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.rectangle(frame, (frame.shape[1] - 100, 0), (frame.shape[1], 100), (255, 0, 0), -1)\n",
    "        cv2.putText(frame, 'Emotion', (frame.shape[1] - 80, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "    def set_glasses_filter(self, points, color_face_redim, filter_weight, filter_height, region_no_transparente, filter_resized):\n",
    "        try:\n",
    "            color_face_redim[int(points[9][1]):int(points[9][1]) + filter_height,\n",
    "            int(points[9][0]): int(points[9][0]) + filter_weight, :][region_no_transparente] = filter_resized[:, :, :3][\n",
    "                region_no_transparente]\n",
    "        except:\n",
    "            color_face_redim[int(points[7][1]):int(points[7][1]) + filter_height,\n",
    "            int(points[7][0]): int(points[7][0]) + filter_weight, :][region_no_transparente] = filter_resized[:, :, :3][\n",
    "                region_no_transparente]\n",
    "\n",
    "    def set_moustache_filter(self, points, color_face_redim, filter_weight, filter_height, region_no_transparente, filter_resized):\n",
    "        color_face_redim[int(points[10][1]):int(points[10][1]) + filter_height,\n",
    "        int(points[5][0]): int(points[5][0]) + filter_weight, :][region_no_transparente] = filter_resized[:, :, :3][\n",
    "                region_no_transparente]\n",
    "\n",
    "    def get_filter(self, filter_image, points, color_face_redim, filter_weight, filter_height, original_shape):\n",
    "        if filter_weight > 0 and filter_height > 0:\n",
    "            filter_resized = cv2.resize(filter_image, (filter_weight, filter_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            region_no_transparente = filter_resized[:, :, :3] != 0\n",
    "\n",
    "            try:\n",
    "                if 'moustache' in self.random_filter:\n",
    "                    self.set_moustache_filter(points, color_face_redim, filter_weight, filter_height, region_no_transparente, filter_resized)\n",
    "                else:\n",
    "                    self.set_glasses_filter(points, color_face_redim, filter_weight, filter_height, region_no_transparente, filter_resized)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            cv2.imshow('filter', color_face_redim)\n",
    "\n",
    "            color_face = cv2.resize(color_face_redim, original_shape, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            return color_face\n",
    "\n",
    "    def get_glasses_filter_dimensions(self, points):\n",
    "        ancho_gafas = int((points[7][0] - points[9][0]))\n",
    "        alto_gafas = int((points[10][1] - points[8][1]))\n",
    "\n",
    "        if ancho_gafas > 0 and alto_gafas > 0:\n",
    "            return points, (ancho_gafas, alto_gafas)\n",
    "\n",
    "        ancho_gafas = int((points[9][0] - points[7][0]))\n",
    "        alto_gafas = int((points[10][1] - points[8][1]))\n",
    "\n",
    "        if ancho_gafas > 0 and alto_gafas > 0:\n",
    "            return points, (ancho_gafas, alto_gafas)\n",
    "\n",
    "        return points, False\n",
    "\n",
    "    def get_moustache_filter_dimensions(self, points):\n",
    "        ancho = int((points[7][0] - points[9][0]))\n",
    "        alto = int((points[14][1] - points[10][1]))\n",
    "\n",
    "        print(1, ancho, alto)\n",
    "        if ancho > 0 and alto > 0:\n",
    "            return points, (ancho, alto)\n",
    "\n",
    "        return points, False\n",
    "\n",
    "    def get_filter_dimensions(self, frame_cara):\n",
    "\n",
    "        points_x, points_y = self.get_points(frame_cara)\n",
    "        points = list(zip(points_x, points_y))\n",
    "        print(self.random_filter)\n",
    "\n",
    "        if 'moustache' in self.random_filter:\n",
    "            return self.get_moustache_filter_dimensions(points)\n",
    "\n",
    "        return self.get_glasses_filter_dimensions(points)\n",
    "\n",
    "    def hand_detection(self, frame):\n",
    "        results = hands.process(frame)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            return results.multi_hand_landmarks[0].landmark\n",
    "\n",
    "    def must_change_filter(self, hand_landmarks):\n",
    "        if hand_landmarks is not None:\n",
    "            if hand_landmarks[8].y * frame.shape[0] <= 110.0 and hand_landmarks[8].x * frame.shape[1] <= 100.0:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def must_predict_emotion(self, hand_landmarks):\n",
    "        if hand_landmarks is not None:\n",
    "            if hand_landmarks[8].y * frame.shape[0] <= 110.0 and hand_landmarks[8].x * frame.shape[1] >= frame.shape[\n",
    "                1] - 100:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def predict_emotion_and_draw_emotion(self,frame_cara):\n",
    "        frame_cara = tf.reshape(frame_cara, (-1, 105, 105, 1))\n",
    "\n",
    "        return emotion_dict[int(np.argmax(model_emotions.predict(frame_cara)))]\n",
    "\n",
    "    def draw_points(self, points,x,y,w,h):\n",
    "         for index, point in self.enumerate_points(points):\n",
    "            #resize points coordinates to original dataframe\n",
    "            point = (point[0] * w / 96, point[1] * h / 96)\n",
    "\n",
    "            #draw cirlce\n",
    "            cv2.circle(self.second_frame, (int(point[0] + x), int(point[1] + y)), 1, (255, 255, 255), 3)\n",
    "\n",
    "            #draw index\n",
    "            cv2.putText(self.second_frame, str(index), (int(point[0] + x), int(point[1] + y)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "    def detect_faces(self, frame, hand_landmarks):\n",
    "        faces = faceCascade.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "        filter_image = cv2.imread(self.random_filter, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            gray_face = gray[y:y + h, x:x + w]\n",
    "            color_face = frame[y:y + h, x:x + w]\n",
    "            frame_cara = cv2.resize(gray_face, (96, 96)) / 255\n",
    "            frame_cara_emotion = cv2.resize(gray_face, (105, 105)) / 255\n",
    "            color_face_redim = cv2.resize(color_face, (96, 96))\n",
    "            original_shape = gray_face.shape\n",
    "\n",
    "            points, filter_dimensions = self.get_filter_dimensions(frame_cara)\n",
    "\n",
    "            self.draw_points(points, x,y, w, h)\n",
    "\n",
    "            if not filter_dimensions:\n",
    "                continue\n",
    "\n",
    "            ancho_gafas = filter_dimensions[0]\n",
    "            alto_gafas = filter_dimensions[1]\n",
    "\n",
    "            selfie_filter = self.get_filter(filter_image, points, color_face_redim, ancho_gafas, alto_gafas, original_shape)\n",
    "\n",
    "            if selfie_filter is not None:\n",
    "                frame[y:y + h, x:x + w] = selfie_filter\n",
    "\n",
    "            if self.must_predict_emotion(hand_landmarks):\n",
    "                self.last_emotion_predicted = self.predict_emotion_and_draw_emotion(frame_cara_emotion)\n",
    "                print(self.last_emotion_predicted)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    handsCascade = cv2.CascadeClassifier('haarCascadeHands/cascadeHands.xml')\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "\n",
    "    cont = 0\n",
    "    last_filter_used = 'filtros/sunglasses.png'\n",
    "    selfie_filters = ['filtros/sunglasses.png', 'filtros/sunglasses_2.png','filtros/sunglasses_3.jpg','filtros/sunglasses_4.png','filtros/sunglasses_5.jpg','filtros/moustache.png','filtros/sunglasses_6.png']\n",
    "\n",
    "    setFiltersActions = SetFiltersActions()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        cap.set(cv2.CAP_PROP_FPS, 16)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # if frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        # Our operations on the frame come here\n",
    "\n",
    "        frame = cv2.flip(frame, 90)\n",
    "        second_frame = frame.copy()\n",
    "\n",
    "        setFiltersActions.second_frame = second_frame\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        setFiltersActions.draw_rectangles(frame)\n",
    "\n",
    "        hand_landmarks = setFiltersActions.hand_detection(frame)\n",
    "\n",
    "        if setFiltersActions.must_change_filter(hand_landmarks):\n",
    "            setFiltersActions.random_filter = random.choice(selfie_filters)\n",
    "\n",
    "        setFiltersActions.detect_faces(frame, hand_landmarks)\n",
    "\n",
    "        cv2.putText(frame, setFiltersActions.last_emotion_predicted, (frame.shape[1] // 2, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6,\n",
    "                            (0, 0, 0), 3)\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.imshow('frame2', second_frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "        cont += 1\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
