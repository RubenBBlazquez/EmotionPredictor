{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](../../../../Documents/Screenshots/screenshot.286.jpg)\n",
    "![](../../../../Documents/Screenshots/screenshot.284.jpg)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "NEURAL_NETWORK_TYPE = 'convolutional'\n",
    "shape = (96, 96, 1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NEURAL_NETWORK_TYPE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgetNeuralNetworkModel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_neural_network_model\n\u001B[1;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m get_neural_network_model(\u001B[43mNEURAL_NETWORK_TYPE\u001B[49m)\n\u001B[0;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'NEURAL_NETWORK_TYPE' is not defined"
     ]
    }
   ],
   "source": [
    "from getNeuralNetworkModel import get_neural_network_model\n",
    "\n",
    "model = get_neural_network_model(NEURAL_NETWORK_TYPE)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_feather('datasets/second_augmented_data.feather').copy()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_in_batches = np.array_split(data, 5)\n",
    "\n",
    "index = 0\n",
    "for batch in data_in_batches:\n",
    "    images = batch['Image'].str.split(' ', expand=True).astype(np.float32).to_numpy().reshape(-1, 96, 96, 1)\n",
    "    points = batch.iloc[:, :-1].to_numpy()\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(images, points, train_size=0.8)\n",
    "\n",
    "    model.fit(train_x, train_y, epochs=500, validation_data=(test_x, test_y))\n",
    "    model.save(f'models/facialPointsPredictor_{NEURAL_NETWORK_TYPE}.h5')\n",
    "\n",
    "    index += 1\n",
    "\n",
    "    print(f'-----------------------------------------------------------------------')\n",
    "    print(f'Batch {index} completed')\n",
    "    print(f'-----------------------------------------------------------------------')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('models/facialPointsPredictor.h5')\n",
    "\n",
    "def get_points(image):\n",
    "    image = tf.reshape(image, (96, 96, 1))\n",
    "    points = model.predict(np.array([image]))[0]\n",
    "\n",
    "    return points[0::2], points[1::2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "glassesCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_lowerbody.xml')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "cont = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "\n",
    "    frame = cv2.flip(frame, 90)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        frame_cara = cv2.resize(frame[y:y + h, x:x + w], (96, 96)) / 255\n",
    "\n",
    "        points_x, points_y = get_points(frame_cara)\n",
    "\n",
    "        points = zip(points_x, points_y)\n",
    "\n",
    "        # cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "        for point in points:\n",
    "            #resize points coordinates to original dataframe\n",
    "            point = (point[0] * w / 96, point[1] * h / 96)\n",
    "\n",
    "            #draw cirlce\n",
    "            cv2.circle(frame, (int(point[0] + x), int(point[1] + y)), 1, (255, 255, 255), 3)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    cont += 1\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
