{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](../../../../Documents/Screenshots/screenshot.286.jpg)\n",
    "![](../../../../Documents/Screenshots/screenshot.284.jpg)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "NEURAL_NETWORK_TYPE = 'convolutional'\n",
    "shape = (96, 96, 1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from getNeuralNetworkModel import get_neural_network_model\n",
    "\n",
    "model = get_neural_network_model(NEURAL_NETWORK_TYPE)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d (ZeroPadding  (None, 102, 102, 1)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 100, 100, 64)      640       \n",
      "                                                                 \n",
      " bn_conv1 (BatchNormalizatio  (None, 100, 100, 64)     256       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 33, 33, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 33, 33, 64)        4160      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 256)       147712    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 256)       65792     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 64)          16448     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         16640     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 64)          16448     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8, 8, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 256)         16640     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 128)         32896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 4, 4, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 4, 4, 512)         590336    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 4, 4, 512)         262656    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 2, 2, 128)         65664     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 2, 2, 512)         66048     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 2, 2, 128)         65664     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 2, 2, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 2, 2, 512)         66048     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " avg_pool (AveragePooling2D)  (None, 1, 1, 512)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              2101248   \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              8390656   \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                61470     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,557,854\n",
      "Trainable params: 12,549,278\n",
      "Non-trainable params: 8,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n0              64.678350          34.973984           31.766794   \n1              65.505260          36.810040           29.923138   \n2              65.537030          37.160828           30.592258   \n3              67.524620          39.423010           27.345154   \n4              69.368210          35.821877           27.131690   \n...                  ...                ...                 ...   \n12835          70.335531          45.014747           28.937791   \n12836          68.865864          53.509493           44.890221   \n12837          67.084800          37.864640           32.048000   \n12838          68.926765          40.364292           28.215250   \n12839          29.887825          37.929546           63.783780   \n\n       right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n0               33.798576                59.095234                35.561687   \n1               38.468390                58.871530                37.413020   \n2               36.814840                60.001550                37.852800   \n3               40.703670                60.000988                39.903340   \n4               36.711098                61.587730                36.711098   \n...                   ...                      ...                      ...   \n12835           37.715209                63.305459                42.455028   \n12836           25.496495                64.246201                49.403304   \n12837           39.294720                60.649600                37.864640   \n12838           37.268463                60.543373                41.268383   \n12839           36.507050                36.050920                39.351513   \n\n       left_eye_outer_corner_x  left_eye_outer_corner_y  \\\n0                    69.674300                36.443310   \n1                    74.702430                37.111530   \n2                    71.073290                37.852800   \n3                    75.848580                40.863670   \n4                    77.592870                36.266460   \n...                        ...                      ...   \n12835                77.163528                46.218708   \n12836                74.321977                60.391891   \n12837                73.163200                38.222160   \n12838                79.173140                42.145077   \n12839                23.725260                39.114430   \n\n       right_eye_inner_corner_x  right_eye_inner_corner_y  ...  nose_tip_y  \\\n0                     36.468163                 34.386280  ...   53.781040   \n1                     35.803295                 38.317802  ...   55.053490   \n2                     35.781677                 37.852800  ...   57.574450   \n3                     37.110104                 40.383340  ...   58.310596   \n4                     34.689823                 37.600266  ...   55.828724   \n...                         ...                       ...  ...         ...   \n12835                 37.071057                 36.508967  ...   59.177164   \n12836                 49.226569                 32.396360  ...   54.640618   \n12837                 38.125600                 39.652240  ...   56.813520   \n12838                 36.489060                 39.898550  ...   60.520744   \n12839                 59.043182                 37.929546  ...   56.907314   \n\n       mouth_left_corner_x  mouth_left_corner_y  mouth_right_corner_x  \\\n0                55.568880            70.237150             35.292492   \n1                71.083920            69.226036             28.113882   \n2                61.731100            77.642330             33.706066   \n3                63.061770            78.145320             33.063587   \n4                68.701180            82.281950             29.799295   \n...                    ...                  ...                   ...   \n12835            61.603550            79.559263             26.959501   \n12836            42.518316            76.304622             18.739519   \n12837            67.084800            74.689840             35.623200   \n12838            67.022240            78.620285             25.992792   \n12839            34.628420            78.462234             67.102410   \n\n       mouth_right_corner_y  mouth_center_top_lip_x  mouth_center_top_lip_y  \\\n0                 69.355400               46.165478               64.947290   \n1                 71.940080               48.468080               67.115295   \n2                 76.258064               46.577805               72.213680   \n3                 78.801155               48.308453               74.866806   \n4                 84.060190               47.360830               72.500890   \n...                     ...                     ...                     ...   \n12835             73.890724               44.155041               71.201909   \n12836             48.613704               31.545283               62.755458   \n12837             75.404880               48.493600               71.114560   \n12838             75.544210               43.974277               76.403700   \n12839             75.380684               50.357040               74.116776   \n\n       mouth_center_bottom_lip_x  mouth_center_bottom_lip_y  \\\n0                      45.871563                  76.114190   \n1                      49.975840                  84.604866   \n2                      46.567740                  84.692130   \n3                      48.964287                  80.440414   \n4                      48.472042                  94.952450   \n...                          ...                        ...   \n12835                  41.872748                  86.641613   \n12836                  22.038553                  70.732551   \n12837                  48.851200                  80.410400   \n12838                  43.995537                  83.684060   \n12839                  50.983955                  82.728660   \n\n                                                   Image  \n0      0.2705 0.298 0.3176 0.3843 0.447 0.4314 0.4314...  \n1      1.0 1.0 1.0 1.0 0.992 1.0 0.7334 0.2235 0.1726...  \n2      1.5044792 1.5276556 1.5124711 1.5124711 1.5124...  \n3      0.1098 0.0902 0.0863 0.0902 0.0863 0.0863 0.07...  \n4      0.8901275 0.87121457 0.88536876 0.9761508 0.93...  \n...                                                  ...  \n12835  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.3882762 0.31...  \n12836  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....  \n12837  36.74599999189377 16.74599999189377 3.24599999...  \n12838  0.714 0.6665 0.6626 0.6353 0.6587 0.6704 0.647...  \n12839  0.6 0.604 0.612 0.612 0.612 0.6157 0.612 0.627...  \n\n[12840 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left_eye_center_x</th>\n      <th>left_eye_center_y</th>\n      <th>right_eye_center_x</th>\n      <th>right_eye_center_y</th>\n      <th>left_eye_inner_corner_x</th>\n      <th>left_eye_inner_corner_y</th>\n      <th>left_eye_outer_corner_x</th>\n      <th>left_eye_outer_corner_y</th>\n      <th>right_eye_inner_corner_x</th>\n      <th>right_eye_inner_corner_y</th>\n      <th>...</th>\n      <th>nose_tip_y</th>\n      <th>mouth_left_corner_x</th>\n      <th>mouth_left_corner_y</th>\n      <th>mouth_right_corner_x</th>\n      <th>mouth_right_corner_y</th>\n      <th>mouth_center_top_lip_x</th>\n      <th>mouth_center_top_lip_y</th>\n      <th>mouth_center_bottom_lip_x</th>\n      <th>mouth_center_bottom_lip_y</th>\n      <th>Image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>64.678350</td>\n      <td>34.973984</td>\n      <td>31.766794</td>\n      <td>33.798576</td>\n      <td>59.095234</td>\n      <td>35.561687</td>\n      <td>69.674300</td>\n      <td>36.443310</td>\n      <td>36.468163</td>\n      <td>34.386280</td>\n      <td>...</td>\n      <td>53.781040</td>\n      <td>55.568880</td>\n      <td>70.237150</td>\n      <td>35.292492</td>\n      <td>69.355400</td>\n      <td>46.165478</td>\n      <td>64.947290</td>\n      <td>45.871563</td>\n      <td>76.114190</td>\n      <td>0.2705 0.298 0.3176 0.3843 0.447 0.4314 0.4314...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>65.505260</td>\n      <td>36.810040</td>\n      <td>29.923138</td>\n      <td>38.468390</td>\n      <td>58.871530</td>\n      <td>37.413020</td>\n      <td>74.702430</td>\n      <td>37.111530</td>\n      <td>35.803295</td>\n      <td>38.317802</td>\n      <td>...</td>\n      <td>55.053490</td>\n      <td>71.083920</td>\n      <td>69.226036</td>\n      <td>28.113882</td>\n      <td>71.940080</td>\n      <td>48.468080</td>\n      <td>67.115295</td>\n      <td>49.975840</td>\n      <td>84.604866</td>\n      <td>1.0 1.0 1.0 1.0 0.992 1.0 0.7334 0.2235 0.1726...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65.537030</td>\n      <td>37.160828</td>\n      <td>30.592258</td>\n      <td>36.814840</td>\n      <td>60.001550</td>\n      <td>37.852800</td>\n      <td>71.073290</td>\n      <td>37.852800</td>\n      <td>35.781677</td>\n      <td>37.852800</td>\n      <td>...</td>\n      <td>57.574450</td>\n      <td>61.731100</td>\n      <td>77.642330</td>\n      <td>33.706066</td>\n      <td>76.258064</td>\n      <td>46.577805</td>\n      <td>72.213680</td>\n      <td>46.567740</td>\n      <td>84.692130</td>\n      <td>1.5044792 1.5276556 1.5124711 1.5124711 1.5124...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67.524620</td>\n      <td>39.423010</td>\n      <td>27.345154</td>\n      <td>40.703670</td>\n      <td>60.000988</td>\n      <td>39.903340</td>\n      <td>75.848580</td>\n      <td>40.863670</td>\n      <td>37.110104</td>\n      <td>40.383340</td>\n      <td>...</td>\n      <td>58.310596</td>\n      <td>63.061770</td>\n      <td>78.145320</td>\n      <td>33.063587</td>\n      <td>78.801155</td>\n      <td>48.308453</td>\n      <td>74.866806</td>\n      <td>48.964287</td>\n      <td>80.440414</td>\n      <td>0.1098 0.0902 0.0863 0.0902 0.0863 0.0863 0.07...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>69.368210</td>\n      <td>35.821877</td>\n      <td>27.131690</td>\n      <td>36.711098</td>\n      <td>61.587730</td>\n      <td>36.711098</td>\n      <td>77.592870</td>\n      <td>36.266460</td>\n      <td>34.689823</td>\n      <td>37.600266</td>\n      <td>...</td>\n      <td>55.828724</td>\n      <td>68.701180</td>\n      <td>82.281950</td>\n      <td>29.799295</td>\n      <td>84.060190</td>\n      <td>47.360830</td>\n      <td>72.500890</td>\n      <td>48.472042</td>\n      <td>94.952450</td>\n      <td>0.8901275 0.87121457 0.88536876 0.9761508 0.93...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12835</th>\n      <td>70.335531</td>\n      <td>45.014747</td>\n      <td>28.937791</td>\n      <td>37.715209</td>\n      <td>63.305459</td>\n      <td>42.455028</td>\n      <td>77.163528</td>\n      <td>46.218708</td>\n      <td>37.071057</td>\n      <td>36.508967</td>\n      <td>...</td>\n      <td>59.177164</td>\n      <td>61.603550</td>\n      <td>79.559263</td>\n      <td>26.959501</td>\n      <td>73.890724</td>\n      <td>44.155041</td>\n      <td>71.201909</td>\n      <td>41.872748</td>\n      <td>86.641613</td>\n      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.3882762 0.31...</td>\n    </tr>\n    <tr>\n      <th>12836</th>\n      <td>68.865864</td>\n      <td>53.509493</td>\n      <td>44.890221</td>\n      <td>25.496495</td>\n      <td>64.246201</td>\n      <td>49.403304</td>\n      <td>74.321977</td>\n      <td>60.391891</td>\n      <td>49.226569</td>\n      <td>32.396360</td>\n      <td>...</td>\n      <td>54.640618</td>\n      <td>42.518316</td>\n      <td>76.304622</td>\n      <td>18.739519</td>\n      <td>48.613704</td>\n      <td>31.545283</td>\n      <td>62.755458</td>\n      <td>22.038553</td>\n      <td>70.732551</td>\n      <td>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0....</td>\n    </tr>\n    <tr>\n      <th>12837</th>\n      <td>67.084800</td>\n      <td>37.864640</td>\n      <td>32.048000</td>\n      <td>39.294720</td>\n      <td>60.649600</td>\n      <td>37.864640</td>\n      <td>73.163200</td>\n      <td>38.222160</td>\n      <td>38.125600</td>\n      <td>39.652240</td>\n      <td>...</td>\n      <td>56.813520</td>\n      <td>67.084800</td>\n      <td>74.689840</td>\n      <td>35.623200</td>\n      <td>75.404880</td>\n      <td>48.493600</td>\n      <td>71.114560</td>\n      <td>48.851200</td>\n      <td>80.410400</td>\n      <td>36.74599999189377 16.74599999189377 3.24599999...</td>\n    </tr>\n    <tr>\n      <th>12838</th>\n      <td>68.926765</td>\n      <td>40.364292</td>\n      <td>28.215250</td>\n      <td>37.268463</td>\n      <td>60.543373</td>\n      <td>41.268383</td>\n      <td>79.173140</td>\n      <td>42.145077</td>\n      <td>36.489060</td>\n      <td>39.898550</td>\n      <td>...</td>\n      <td>60.520744</td>\n      <td>67.022240</td>\n      <td>78.620285</td>\n      <td>25.992792</td>\n      <td>75.544210</td>\n      <td>43.974277</td>\n      <td>76.403700</td>\n      <td>43.995537</td>\n      <td>83.684060</td>\n      <td>0.714 0.6665 0.6626 0.6353 0.6587 0.6704 0.647...</td>\n    </tr>\n    <tr>\n      <th>12839</th>\n      <td>29.887825</td>\n      <td>37.929546</td>\n      <td>63.783780</td>\n      <td>36.507050</td>\n      <td>36.050920</td>\n      <td>39.351513</td>\n      <td>23.725260</td>\n      <td>39.114430</td>\n      <td>59.043182</td>\n      <td>37.929546</td>\n      <td>...</td>\n      <td>56.907314</td>\n      <td>34.628420</td>\n      <td>78.462234</td>\n      <td>67.102410</td>\n      <td>75.380684</td>\n      <td>50.357040</td>\n      <td>74.116776</td>\n      <td>50.983955</td>\n      <td>82.728660</td>\n      <td>0.6 0.604 0.612 0.612 0.612 0.6157 0.612 0.627...</td>\n    </tr>\n  </tbody>\n</table>\n<p>12840 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather('datasets/second_augmented_data.feather').copy()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "65/65 [==============================] - 20s 57ms/step - loss: 331.8722 - accuracy: 0.3627 - val_loss: 1448.5557 - val_accuracy: 0.6187\n",
      "Epoch 2/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 148.0042 - accuracy: 0.4698 - val_loss: 727.2751 - val_accuracy: 0.6187\n",
      "Epoch 3/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 144.9501 - accuracy: 0.5029 - val_loss: 289.3633 - val_accuracy: 0.6187\n",
      "Epoch 4/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 146.6987 - accuracy: 0.5180 - val_loss: 259.2032 - val_accuracy: 0.6187\n",
      "Epoch 5/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 143.2709 - accuracy: 0.5414 - val_loss: 344.1561 - val_accuracy: 0.6187\n",
      "Epoch 6/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 144.5877 - accuracy: 0.5560 - val_loss: 147.5779 - val_accuracy: 0.6187\n",
      "Epoch 7/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 143.5727 - accuracy: 0.5652 - val_loss: 125.7769 - val_accuracy: 0.6187\n",
      "Epoch 8/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.9475 - accuracy: 0.5706 - val_loss: 127.6080 - val_accuracy: 0.6187\n",
      "Epoch 9/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 140.7144 - accuracy: 0.5818 - val_loss: 132.0039 - val_accuracy: 0.6187\n",
      "Epoch 10/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 142.6010 - accuracy: 0.5823 - val_loss: 134.9991 - val_accuracy: 0.6187\n",
      "Epoch 11/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 143.6967 - accuracy: 0.5993 - val_loss: 136.4612 - val_accuracy: 0.5253\n",
      "Epoch 12/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 142.3596 - accuracy: 0.6037 - val_loss: 134.5250 - val_accuracy: 0.6187\n",
      "Epoch 13/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 143.5310 - accuracy: 0.5993 - val_loss: 132.0771 - val_accuracy: 0.5253\n",
      "Epoch 14/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 142.3583 - accuracy: 0.6037 - val_loss: 164.5509 - val_accuracy: 0.6187\n",
      "Epoch 15/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 145.3443 - accuracy: 0.6056 - val_loss: 129.3913 - val_accuracy: 0.6187\n",
      "Epoch 16/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 144.6392 - accuracy: 0.6047 - val_loss: 125.2494 - val_accuracy: 0.6187\n",
      "Epoch 17/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 141.8237 - accuracy: 0.6037 - val_loss: 128.4503 - val_accuracy: 0.6187\n",
      "Epoch 18/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 142.7676 - accuracy: 0.6115 - val_loss: 129.2029 - val_accuracy: 0.6187\n",
      "Epoch 19/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 141.1246 - accuracy: 0.6134 - val_loss: 126.7560 - val_accuracy: 0.6187\n",
      "Epoch 20/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 142.0497 - accuracy: 0.6105 - val_loss: 143.9689 - val_accuracy: 0.6187\n",
      "Epoch 21/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 139.2739 - accuracy: 0.6056 - val_loss: 125.5133 - val_accuracy: 0.6187\n",
      "Epoch 22/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 139.6006 - accuracy: 0.6095 - val_loss: 131.2972 - val_accuracy: 0.6187\n",
      "Epoch 23/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 140.9195 - accuracy: 0.6139 - val_loss: 150.2010 - val_accuracy: 0.6187\n",
      "Epoch 24/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 140.0144 - accuracy: 0.6115 - val_loss: 130.1552 - val_accuracy: 0.6187\n",
      "Epoch 25/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.1955 - accuracy: 0.6061 - val_loss: 126.5103 - val_accuracy: 0.6187\n",
      "Epoch 26/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 140.0787 - accuracy: 0.6149 - val_loss: 136.3916 - val_accuracy: 0.6187\n",
      "Epoch 27/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 140.9571 - accuracy: 0.6047 - val_loss: 241.5193 - val_accuracy: 0.6187\n",
      "Epoch 28/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 141.1808 - accuracy: 0.6134 - val_loss: 144.2673 - val_accuracy: 0.6187\n",
      "Epoch 29/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 145.2792 - accuracy: 0.6056 - val_loss: 139.8418 - val_accuracy: 0.6187\n",
      "Epoch 30/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 140.6644 - accuracy: 0.6095 - val_loss: 150.8631 - val_accuracy: 0.6187\n",
      "Epoch 31/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 140.0772 - accuracy: 0.6115 - val_loss: 133.8766 - val_accuracy: 0.6187\n",
      "Epoch 32/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.3428 - accuracy: 0.6139 - val_loss: 125.0663 - val_accuracy: 0.6187\n",
      "Epoch 33/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 140.4316 - accuracy: 0.6134 - val_loss: 2168.6208 - val_accuracy: 0.6187\n",
      "Epoch 34/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.1878 - accuracy: 0.6105 - val_loss: 126.8036 - val_accuracy: 0.6187\n",
      "Epoch 35/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 138.4492 - accuracy: 0.6144 - val_loss: 128.5189 - val_accuracy: 0.6187\n",
      "Epoch 36/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 141.8981 - accuracy: 0.6061 - val_loss: 130.8164 - val_accuracy: 0.6187\n",
      "Epoch 37/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 138.6724 - accuracy: 0.6042 - val_loss: 168.2405 - val_accuracy: 0.2237\n",
      "Epoch 38/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.6879 - accuracy: 0.6125 - val_loss: 146.3253 - val_accuracy: 0.6187\n",
      "Epoch 39/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 138.6366 - accuracy: 0.6134 - val_loss: 154.7549 - val_accuracy: 0.6187\n",
      "Epoch 40/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 138.5891 - accuracy: 0.6125 - val_loss: 153.3762 - val_accuracy: 0.6187\n",
      "Epoch 41/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 137.6058 - accuracy: 0.6061 - val_loss: 125.9397 - val_accuracy: 0.6187\n",
      "Epoch 42/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 137.5269 - accuracy: 0.6120 - val_loss: 123.1532 - val_accuracy: 0.6187\n",
      "Epoch 43/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 137.9875 - accuracy: 0.6173 - val_loss: 290.4951 - val_accuracy: 0.6187\n",
      "Epoch 44/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.8686 - accuracy: 0.6164 - val_loss: 156.2432 - val_accuracy: 0.6187\n",
      "Epoch 45/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 140.8496 - accuracy: 0.6032 - val_loss: 182.6578 - val_accuracy: 0.6187\n",
      "Epoch 46/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 140.6487 - accuracy: 0.6125 - val_loss: 129.1178 - val_accuracy: 0.6187\n",
      "Epoch 47/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 140.2890 - accuracy: 0.6159 - val_loss: 162.7806 - val_accuracy: 0.6187\n",
      "Epoch 48/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.9886 - accuracy: 0.6134 - val_loss: 141.9195 - val_accuracy: 0.6187\n",
      "Epoch 49/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.3103 - accuracy: 0.6100 - val_loss: 152.4095 - val_accuracy: 0.6187\n",
      "Epoch 50/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 136.9130 - accuracy: 0.6130 - val_loss: 127.0005 - val_accuracy: 0.6187\n",
      "Epoch 51/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 136.2938 - accuracy: 0.6100 - val_loss: 124.9355 - val_accuracy: 0.6187\n",
      "Epoch 52/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 134.4838 - accuracy: 0.6115 - val_loss: 136.1570 - val_accuracy: 0.6187\n",
      "Epoch 53/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 141.0231 - accuracy: 0.6168 - val_loss: 140.4065 - val_accuracy: 0.6187\n",
      "Epoch 54/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 139.2721 - accuracy: 0.6081 - val_loss: 137.9648 - val_accuracy: 0.6187\n",
      "Epoch 55/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 138.6848 - accuracy: 0.6115 - val_loss: 133.1631 - val_accuracy: 0.6187\n",
      "Epoch 56/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 136.6630 - accuracy: 0.6159 - val_loss: 130.6171 - val_accuracy: 0.6187\n",
      "Epoch 57/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 136.7922 - accuracy: 0.6178 - val_loss: 132.3569 - val_accuracy: 0.6187\n",
      "Epoch 58/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 134.1904 - accuracy: 0.6095 - val_loss: 155.6747 - val_accuracy: 0.5233\n",
      "Epoch 59/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 136.9621 - accuracy: 0.6125 - val_loss: 153.0045 - val_accuracy: 0.6187\n",
      "Epoch 60/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 134.2557 - accuracy: 0.6125 - val_loss: 145.2184 - val_accuracy: 0.6187\n",
      "Epoch 61/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 132.5825 - accuracy: 0.6164 - val_loss: 205.6956 - val_accuracy: 0.6187\n",
      "Epoch 62/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 132.1912 - accuracy: 0.6115 - val_loss: 120.8858 - val_accuracy: 0.6187\n",
      "Epoch 63/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 132.6681 - accuracy: 0.6013 - val_loss: 141.9370 - val_accuracy: 0.6187\n",
      "Epoch 64/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 135.1700 - accuracy: 0.6149 - val_loss: 135.0855 - val_accuracy: 0.6187\n",
      "Epoch 65/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 134.5025 - accuracy: 0.6081 - val_loss: 147.2228 - val_accuracy: 0.6187\n",
      "Epoch 66/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 140.9495 - accuracy: 0.6091 - val_loss: 153.3738 - val_accuracy: 0.6187\n",
      "Epoch 67/500\n",
      "65/65 [==============================] - 3s 49ms/step - loss: 134.7780 - accuracy: 0.6076 - val_loss: 126.4635 - val_accuracy: 0.6187\n",
      "Epoch 68/500\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 134.1102 - accuracy: 0.6110 - val_loss: 147.0657 - val_accuracy: 0.6187\n",
      "Epoch 69/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 132.2793 - accuracy: 0.6125 - val_loss: 134.5875 - val_accuracy: 0.6187\n",
      "Epoch 70/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 132.6205 - accuracy: 0.6081 - val_loss: 128.5692 - val_accuracy: 0.6187\n",
      "Epoch 71/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 130.8345 - accuracy: 0.6105 - val_loss: 158.2197 - val_accuracy: 0.6187\n",
      "Epoch 72/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 131.1757 - accuracy: 0.6120 - val_loss: 136.8528 - val_accuracy: 0.6187\n",
      "Epoch 73/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 131.3164 - accuracy: 0.6095 - val_loss: 148.2001 - val_accuracy: 0.6187\n",
      "Epoch 74/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 132.7586 - accuracy: 0.6115 - val_loss: 584.7271 - val_accuracy: 0.6187\n",
      "Epoch 75/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 129.3096 - accuracy: 0.6120 - val_loss: 463.8724 - val_accuracy: 0.6187\n",
      "Epoch 76/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 127.7657 - accuracy: 0.6091 - val_loss: 147.6090 - val_accuracy: 0.6187\n",
      "Epoch 77/500\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 129.5057 - accuracy: 0.6095 - val_loss: 134.4006 - val_accuracy: 0.6187\n",
      "Epoch 78/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 127.5991 - accuracy: 0.6066 - val_loss: 132.3999 - val_accuracy: 0.6187\n",
      "Epoch 79/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 129.1988 - accuracy: 0.6125 - val_loss: 141.7426 - val_accuracy: 0.6187\n",
      "Epoch 80/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 126.8023 - accuracy: 0.6066 - val_loss: 141.8160 - val_accuracy: 0.6187\n",
      "Epoch 81/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 125.8765 - accuracy: 0.6154 - val_loss: 121.4007 - val_accuracy: 0.6187\n",
      "Epoch 82/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 126.9895 - accuracy: 0.6149 - val_loss: 138.6276 - val_accuracy: 0.6187\n",
      "Epoch 83/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 125.9149 - accuracy: 0.6178 - val_loss: 145.4941 - val_accuracy: 0.6187\n",
      "Epoch 84/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 125.6707 - accuracy: 0.6130 - val_loss: 126.9727 - val_accuracy: 0.6187\n",
      "Epoch 85/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 125.3688 - accuracy: 0.6139 - val_loss: 121.1356 - val_accuracy: 0.6187\n",
      "Epoch 86/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 125.3105 - accuracy: 0.6149 - val_loss: 132.4400 - val_accuracy: 0.6187\n",
      "Epoch 87/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 122.3872 - accuracy: 0.6100 - val_loss: 125.8537 - val_accuracy: 0.6187\n",
      "Epoch 88/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 120.4756 - accuracy: 0.6134 - val_loss: 136.8224 - val_accuracy: 0.5253\n",
      "Epoch 89/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 121.6133 - accuracy: 0.6168 - val_loss: 124.4790 - val_accuracy: 0.6187\n",
      "Epoch 90/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 119.2843 - accuracy: 0.6120 - val_loss: 111.9517 - val_accuracy: 0.5253\n",
      "Epoch 91/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 119.3941 - accuracy: 0.6081 - val_loss: 122.0742 - val_accuracy: 0.6187\n",
      "Epoch 92/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 122.1493 - accuracy: 0.6168 - val_loss: 164.8320 - val_accuracy: 0.6187\n",
      "Epoch 93/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 118.2145 - accuracy: 0.6110 - val_loss: 137.9874 - val_accuracy: 0.6187\n",
      "Epoch 94/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 117.3493 - accuracy: 0.6091 - val_loss: 142.6965 - val_accuracy: 0.5253\n",
      "Epoch 95/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 117.4770 - accuracy: 0.6134 - val_loss: 127.3695 - val_accuracy: 0.6187\n",
      "Epoch 96/500\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 114.9217 - accuracy: 0.6159 - val_loss: 124.9758 - val_accuracy: 0.6187\n",
      "Epoch 97/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 110.7989 - accuracy: 0.6061 - val_loss: 141.5076 - val_accuracy: 0.6187\n",
      "Epoch 98/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 115.2144 - accuracy: 0.6193 - val_loss: 138.6073 - val_accuracy: 0.5253\n",
      "Epoch 99/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 112.9191 - accuracy: 0.6056 - val_loss: 160.6507 - val_accuracy: 0.6187\n",
      "Epoch 100/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 109.4967 - accuracy: 0.6183 - val_loss: 159.1923 - val_accuracy: 0.6187\n",
      "Epoch 101/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 110.7780 - accuracy: 0.6154 - val_loss: 123.1326 - val_accuracy: 0.6187\n",
      "Epoch 102/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 107.1889 - accuracy: 0.6134 - val_loss: 159.7183 - val_accuracy: 0.6187\n",
      "Epoch 103/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 109.0612 - accuracy: 0.6159 - val_loss: 128.3932 - val_accuracy: 0.6187\n",
      "Epoch 104/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 102.8489 - accuracy: 0.6095 - val_loss: 122.7640 - val_accuracy: 0.6187\n",
      "Epoch 105/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 106.9600 - accuracy: 0.6173 - val_loss: 126.0833 - val_accuracy: 0.6187\n",
      "Epoch 106/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 103.9990 - accuracy: 0.6105 - val_loss: 104.0167 - val_accuracy: 0.6187\n",
      "Epoch 107/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 100.6757 - accuracy: 0.6188 - val_loss: 243.6996 - val_accuracy: 0.6167\n",
      "Epoch 108/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 101.0969 - accuracy: 0.6154 - val_loss: 140.6825 - val_accuracy: 0.6187\n",
      "Epoch 109/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 100.7165 - accuracy: 0.6183 - val_loss: 123.9147 - val_accuracy: 0.6187\n",
      "Epoch 110/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 98.3654 - accuracy: 0.6115 - val_loss: 134.2991 - val_accuracy: 0.6206\n",
      "Epoch 111/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 93.8696 - accuracy: 0.6178 - val_loss: 178.0544 - val_accuracy: 0.6128\n",
      "Epoch 112/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 99.3205 - accuracy: 0.6130 - val_loss: 118.5164 - val_accuracy: 0.6187\n",
      "Epoch 113/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 92.3659 - accuracy: 0.6164 - val_loss: 114.0789 - val_accuracy: 0.6187\n",
      "Epoch 114/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 91.1933 - accuracy: 0.6144 - val_loss: 126.2049 - val_accuracy: 0.6187\n",
      "Epoch 115/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 93.0817 - accuracy: 0.6105 - val_loss: 128.4951 - val_accuracy: 0.6187\n",
      "Epoch 116/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 91.2180 - accuracy: 0.6134 - val_loss: 128.8893 - val_accuracy: 0.6012\n",
      "Epoch 117/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 90.1965 - accuracy: 0.6154 - val_loss: 134.7015 - val_accuracy: 0.6187\n",
      "Epoch 118/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 86.6890 - accuracy: 0.6125 - val_loss: 122.6165 - val_accuracy: 0.6167\n",
      "Epoch 119/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 86.2316 - accuracy: 0.6115 - val_loss: 96.1403 - val_accuracy: 0.5195\n",
      "Epoch 120/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 83.9630 - accuracy: 0.6100 - val_loss: 167.5863 - val_accuracy: 0.6206\n",
      "Epoch 121/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 84.3643 - accuracy: 0.6134 - val_loss: 111.0792 - val_accuracy: 0.6187\n",
      "Epoch 122/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 107.1148 - accuracy: 0.6178 - val_loss: 182.4192 - val_accuracy: 0.5253\n",
      "Epoch 123/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 88.6346 - accuracy: 0.6154 - val_loss: 191.6729 - val_accuracy: 0.6109\n",
      "Epoch 124/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 86.6936 - accuracy: 0.6164 - val_loss: 192.1105 - val_accuracy: 0.6187\n",
      "Epoch 125/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 78.5937 - accuracy: 0.6149 - val_loss: 101.4139 - val_accuracy: 0.6167\n",
      "Epoch 126/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 88.0494 - accuracy: 0.6144 - val_loss: 110.6714 - val_accuracy: 0.6187\n",
      "Epoch 127/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 78.1911 - accuracy: 0.6115 - val_loss: 149.4163 - val_accuracy: 0.5486\n",
      "Epoch 128/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 121.8259 - accuracy: 0.6086 - val_loss: 119.5686 - val_accuracy: 0.6187\n",
      "Epoch 129/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 106.5173 - accuracy: 0.6188 - val_loss: 116.9836 - val_accuracy: 0.6187\n",
      "Epoch 130/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 97.6419 - accuracy: 0.6183 - val_loss: 116.9266 - val_accuracy: 0.6187\n",
      "Epoch 131/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 89.7510 - accuracy: 0.6203 - val_loss: 125.7920 - val_accuracy: 0.6187\n",
      "Epoch 132/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 86.1005 - accuracy: 0.6159 - val_loss: 110.1224 - val_accuracy: 0.6187\n",
      "Epoch 133/500\n",
      "65/65 [==============================] - 3s 48ms/step - loss: 82.3681 - accuracy: 0.6120 - val_loss: 108.0800 - val_accuracy: 0.6187\n",
      "Epoch 134/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 79.7281 - accuracy: 0.6139 - val_loss: 97.9143 - val_accuracy: 0.6187\n",
      "Epoch 135/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 77.2603 - accuracy: 0.6091 - val_loss: 100.1767 - val_accuracy: 0.6148\n",
      "Epoch 136/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 73.9917 - accuracy: 0.6105 - val_loss: 94.8130 - val_accuracy: 0.6167\n",
      "Epoch 137/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 72.5843 - accuracy: 0.6144 - val_loss: 105.8504 - val_accuracy: 0.6167\n",
      "Epoch 138/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 77.4048 - accuracy: 0.6115 - val_loss: 89.5502 - val_accuracy: 0.6187\n",
      "Epoch 139/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 72.8544 - accuracy: 0.6120 - val_loss: 89.9930 - val_accuracy: 0.6109\n",
      "Epoch 140/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 66.4568 - accuracy: 0.6100 - val_loss: 115.3806 - val_accuracy: 0.6128\n",
      "Epoch 141/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 66.4696 - accuracy: 0.6105 - val_loss: 105.0349 - val_accuracy: 0.6148\n",
      "Epoch 142/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 62.0932 - accuracy: 0.6110 - val_loss: 101.9588 - val_accuracy: 0.6089\n",
      "Epoch 143/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 60.3216 - accuracy: 0.6091 - val_loss: 85.2244 - val_accuracy: 0.6187\n",
      "Epoch 144/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 56.7600 - accuracy: 0.6164 - val_loss: 92.9406 - val_accuracy: 0.6265\n",
      "Epoch 145/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 52.4837 - accuracy: 0.6105 - val_loss: 107.1815 - val_accuracy: 0.6187\n",
      "Epoch 146/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 48.5851 - accuracy: 0.6027 - val_loss: 92.8540 - val_accuracy: 0.6226\n",
      "Epoch 147/500\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 49.7389 - accuracy: 0.6095 - val_loss: 102.4541 - val_accuracy: 0.6362\n",
      "Epoch 148/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 48.3177 - accuracy: 0.6154 - val_loss: 98.2429 - val_accuracy: 0.6401\n",
      "Epoch 149/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 52.0845 - accuracy: 0.6178 - val_loss: 158.6120 - val_accuracy: 0.6167\n",
      "Epoch 150/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 49.2770 - accuracy: 0.6232 - val_loss: 113.4829 - val_accuracy: 0.6265\n",
      "Epoch 151/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 48.3049 - accuracy: 0.6134 - val_loss: 91.6554 - val_accuracy: 0.6342\n",
      "Epoch 152/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 50.8867 - accuracy: 0.6188 - val_loss: 121.4223 - val_accuracy: 0.6187\n",
      "Epoch 153/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 40.7416 - accuracy: 0.6125 - val_loss: 90.2000 - val_accuracy: 0.6420\n",
      "Epoch 154/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 44.7788 - accuracy: 0.6173 - val_loss: 81.6209 - val_accuracy: 0.6401\n",
      "Epoch 155/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 51.2912 - accuracy: 0.6105 - val_loss: 77.6174 - val_accuracy: 0.6381\n",
      "Epoch 156/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 41.4573 - accuracy: 0.6237 - val_loss: 86.9811 - val_accuracy: 0.6459\n",
      "Epoch 157/500\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 38.5686 - accuracy: 0.6271 - val_loss: 82.1781 - val_accuracy: 0.6440\n",
      "Epoch 158/500\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 40.9295 - accuracy: 0.6305 - val_loss: 89.7206 - val_accuracy: 0.6498\n",
      "Epoch 159/500\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 39.1964 - accuracy: 0.6261 - val_loss: 111.2355 - val_accuracy: 0.6284\n",
      "Epoch 160/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 33.1389 - accuracy: 0.6261 - val_loss: 149.3186 - val_accuracy: 0.5798\n",
      "Epoch 161/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 36.6050 - accuracy: 0.6480 - val_loss: 104.9188 - val_accuracy: 0.6440\n",
      "Epoch 162/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 35.3568 - accuracy: 0.6407 - val_loss: 111.3803 - val_accuracy: 0.6440\n",
      "Epoch 163/500\n",
      "65/65 [==============================] - 3s 46ms/step - loss: 41.0495 - accuracy: 0.6392 - val_loss: 157.4428 - val_accuracy: 0.6206\n",
      "Epoch 164/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 32.0909 - accuracy: 0.6426 - val_loss: 130.4940 - val_accuracy: 0.6284\n",
      "Epoch 165/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 26.9037 - accuracy: 0.6543 - val_loss: 99.5066 - val_accuracy: 0.6576\n",
      "Epoch 166/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 27.2939 - accuracy: 0.6456 - val_loss: 81.9574 - val_accuracy: 0.6693\n",
      "Epoch 167/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 29.5079 - accuracy: 0.6349 - val_loss: 75.0281 - val_accuracy: 0.6926\n",
      "Epoch 168/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 35.5145 - accuracy: 0.6324 - val_loss: 78.7343 - val_accuracy: 0.6868\n",
      "Epoch 169/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 25.9288 - accuracy: 0.6436 - val_loss: 105.7103 - val_accuracy: 0.6634\n",
      "Epoch 170/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 29.3528 - accuracy: 0.6490 - val_loss: 80.7307 - val_accuracy: 0.6634\n",
      "Epoch 171/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 33.3534 - accuracy: 0.6256 - val_loss: 81.9514 - val_accuracy: 0.6732\n",
      "Epoch 172/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 26.0903 - accuracy: 0.6378 - val_loss: 88.2923 - val_accuracy: 0.6926\n",
      "Epoch 173/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 26.5376 - accuracy: 0.6485 - val_loss: 93.4475 - val_accuracy: 0.6887\n",
      "Epoch 174/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 26.1222 - accuracy: 0.6607 - val_loss: 99.1419 - val_accuracy: 0.6809\n",
      "Epoch 175/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 33.4526 - accuracy: 0.6514 - val_loss: 119.0358 - val_accuracy: 0.6381\n",
      "Epoch 176/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 29.5110 - accuracy: 0.6480 - val_loss: 64.5649 - val_accuracy: 0.6907\n",
      "Epoch 177/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 25.4927 - accuracy: 0.6587 - val_loss: 81.5951 - val_accuracy: 0.6518\n",
      "Epoch 178/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 23.4219 - accuracy: 0.6582 - val_loss: 73.8904 - val_accuracy: 0.6965\n",
      "Epoch 179/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 22.6868 - accuracy: 0.6538 - val_loss: 102.5798 - val_accuracy: 0.6926\n",
      "Epoch 180/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 25.1478 - accuracy: 0.6548 - val_loss: 96.1577 - val_accuracy: 0.6887\n",
      "Epoch 181/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 23.8077 - accuracy: 0.6641 - val_loss: 162.2378 - val_accuracy: 0.6187\n",
      "Epoch 182/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 25.0820 - accuracy: 0.6553 - val_loss: 98.7472 - val_accuracy: 0.6323\n",
      "Epoch 183/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 23.4259 - accuracy: 0.6500 - val_loss: 125.8235 - val_accuracy: 0.6362\n",
      "Epoch 184/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 20.8916 - accuracy: 0.6504 - val_loss: 86.7051 - val_accuracy: 0.6673\n",
      "Epoch 185/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 21.9518 - accuracy: 0.6524 - val_loss: 137.5618 - val_accuracy: 0.6342\n",
      "Epoch 186/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 28.9928 - accuracy: 0.6558 - val_loss: 78.8372 - val_accuracy: 0.6790\n",
      "Epoch 187/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 24.8664 - accuracy: 0.6553 - val_loss: 100.0158 - val_accuracy: 0.6323\n",
      "Epoch 188/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 20.3744 - accuracy: 0.6607 - val_loss: 91.1104 - val_accuracy: 0.6829\n",
      "Epoch 189/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 25.2392 - accuracy: 0.6470 - val_loss: 108.3815 - val_accuracy: 0.6401\n",
      "Epoch 190/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 26.6101 - accuracy: 0.6685 - val_loss: 153.9949 - val_accuracy: 0.6187\n",
      "Epoch 191/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 22.1444 - accuracy: 0.6592 - val_loss: 179.3507 - val_accuracy: 0.6265\n",
      "Epoch 192/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 27.6423 - accuracy: 0.6777 - val_loss: 157.8757 - val_accuracy: 0.6304\n",
      "Epoch 193/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 24.0621 - accuracy: 0.6519 - val_loss: 76.6293 - val_accuracy: 0.6926\n",
      "Epoch 194/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 27.7245 - accuracy: 0.6577 - val_loss: 269.1014 - val_accuracy: 0.6070\n",
      "Epoch 195/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 36.0953 - accuracy: 0.6641 - val_loss: 87.2445 - val_accuracy: 0.6693\n",
      "Epoch 196/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 23.5754 - accuracy: 0.6543 - val_loss: 132.8231 - val_accuracy: 0.6342\n",
      "Epoch 197/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 21.1914 - accuracy: 0.6641 - val_loss: 139.7079 - val_accuracy: 0.6304\n",
      "Epoch 198/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 24.1080 - accuracy: 0.6538 - val_loss: 153.1214 - val_accuracy: 0.6226\n",
      "Epoch 199/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 22.1761 - accuracy: 0.6592 - val_loss: 77.2155 - val_accuracy: 0.6926\n",
      "Epoch 200/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 34.0353 - accuracy: 0.6543 - val_loss: 82.9582 - val_accuracy: 0.6615\n",
      "Epoch 201/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 24.9013 - accuracy: 0.6324 - val_loss: 86.7565 - val_accuracy: 0.6790\n",
      "Epoch 202/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 19.2895 - accuracy: 0.6529 - val_loss: 140.2754 - val_accuracy: 0.6342\n",
      "Epoch 203/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 18.3428 - accuracy: 0.6563 - val_loss: 81.0912 - val_accuracy: 0.6829\n",
      "Epoch 204/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 25.7637 - accuracy: 0.6558 - val_loss: 112.6934 - val_accuracy: 0.6420\n",
      "Epoch 205/500\n",
      "65/65 [==============================] - 3s 45ms/step - loss: 22.5929 - accuracy: 0.6655 - val_loss: 86.5071 - val_accuracy: 0.6732\n",
      "Epoch 206/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 25.2904 - accuracy: 0.6597 - val_loss: 87.3882 - val_accuracy: 0.6946\n",
      "Epoch 207/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 23.2947 - accuracy: 0.6519 - val_loss: 88.5728 - val_accuracy: 0.6848\n",
      "Epoch 208/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 23.1279 - accuracy: 0.6631 - val_loss: 77.8617 - val_accuracy: 0.7023\n",
      "Epoch 209/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 22.4032 - accuracy: 0.6480 - val_loss: 84.8117 - val_accuracy: 0.6829\n",
      "Epoch 210/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 21.4915 - accuracy: 0.6573 - val_loss: 97.7736 - val_accuracy: 0.6926\n",
      "Epoch 211/500\n",
      "65/65 [==============================] - 3s 42ms/step - loss: 22.9877 - accuracy: 0.6577 - val_loss: 83.6923 - val_accuracy: 0.6984\n",
      "Epoch 212/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 26.6232 - accuracy: 0.6689 - val_loss: 148.2266 - val_accuracy: 0.6187\n",
      "Epoch 213/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 23.3718 - accuracy: 0.6485 - val_loss: 168.6947 - val_accuracy: 0.6226\n",
      "Epoch 214/500\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 29.2524 - accuracy: 0.6602 - val_loss: 156.4249 - val_accuracy: 0.6187\n",
      "Epoch 215/500\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 20.6084 - accuracy: 0.6553 - val_loss: 125.3831 - val_accuracy: 0.6401\n",
      "Epoch 216/500\n",
      "33/65 [==============>...............] - ETA: 1s - loss: 21.0338 - accuracy: 0.6477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_in_batches = np.array_split(data, 5)\n",
    "\n",
    "index = 0\n",
    "for batch in data_in_batches:\n",
    "    images = batch['Image'].str.split(' ', expand=True).astype(np.float32).to_numpy().reshape(-1, 96, 96, 1)\n",
    "    points = batch.iloc[:, :-1].to_numpy()\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(images, points, train_size=0.8)\n",
    "\n",
    "    model.fit(train_x, train_y, epochs=500, validation_data=(test_x, test_y))\n",
    "    model.save(f'models/facialPointsPredictor_{NEURAL_NETWORK_TYPE}.h5')\n",
    "\n",
    "    index += 1\n",
    "\n",
    "    print(f'-----------------------------------------------------------------------')\n",
    "    print(f'Batch {index} completed')\n",
    "    print(f'-----------------------------------------------------------------------')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/facialPointsPredictor_convolutional.h5')\n",
    "\n",
    "\n",
    "def get_points(image):\n",
    "    image = tf.reshape(image, (96, 96, 1))\n",
    "    points = model.predict(np.array([image]))[0]\n",
    "\n",
    "    return points[0::2]*255, points[1::2]*255"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "glassesCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_lowerbody.xml')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "cont = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "\n",
    "    frame = cv2.flip(frame, 90)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        frame_cara = cv2.resize(frame[y:y + h, x:x + w], (96, 96)) / 255\n",
    "\n",
    "        points_x, points_y = get_points(frame_cara)\n",
    "\n",
    "        points = zip(points_x, points_y)\n",
    "\n",
    "        # cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "        for point in points:\n",
    "            #resize points coordinates to original dataframe\n",
    "            point = (point[0] * w / 96, point[1] * h / 96)\n",
    "\n",
    "            #draw cirlce\n",
    "            cv2.circle(frame, (int(point[0] + x), int(point[1] + y)), 1, (255, 255, 255), 3)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    cont += 1\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
